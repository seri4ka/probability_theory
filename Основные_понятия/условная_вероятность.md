# Условная вероятность

**Условная вероятность** — это вероятность наступления события \( A \) при условии, что другое событие \( B \) уже произошло. Обозначается как \( P(A | B) \).

## Определение условной вероятности

Условная вероятность события \( A \) при условии события \( B \) определяется как:
\[
P(A | B) = \frac{P(A \cap B)}{P(B)}
\]
где \( P(B) > 0 \). Это отношение вероятности совместного наступления событий \( A \) и \( B \) к вероятности наступления события \( B \).

### Пример
Предположим, что мы подбрасываем кубик. Пусть событие \( A \) — выпадение четного числа, а событие \( B \) — выпадение числа больше 3. Тогда:
- \( A = \{2, 4, 6\} \)
- \( B = \{4, 5, 6\} \)
- \( A \cap B = \{4, 6\} \)

Если \( P(A) = \frac{1}{2} \), \( P(B) = \frac{1}{2} \), и \( P(A \cap B) = \frac{1}{3} \), то:
\[
P(A | B) = \frac{P(A \cap B)}{P(B)} = \frac{\frac{1}{3}}{\frac{1}{2}} = \frac{2}{3}
\]

## Формула полной вероятности

Если события \( B_1, B_2, \dots, B_n \) образуют полную группу попарно несовместных событий и \( P(B_i) > 0 \) для всех \( i \), то вероятность события \( A \) можно найти по формуле полной вероятности:
\[
P(A) = \sum_{i=1}^{n} P(A | B_i) P(B_i)
\]
Эта формула полезна, когда событие \( A \) зависит от того, какое из событий \( B_i \) произошло.

### Пример
Пусть есть два мешка с шарами. В первом мешке 3 белых и 2 черных шара, во втором — 4 белых и 1 черный шар. Мы случайно выбираем мешок (оба мешка выбираются с равной вероятностью) и вытаскиваем из него случайный шар. Какова вероятность вытащить белый шар?

Пусть \( B_1 \) — событие выбора первого мешка, а \( B_2 \) — событие выбора второго мешка. Тогда:
- \( P(B_1) = P(B_2) = 0.5 \)
- \( P(\text{белый} | B_1) = \frac{3}{5} \)
- \( P(\text{белый} | B_2) = \frac{4}{5} \)

По формуле полной вероятности:
\[
P(\text{белый}) = P(\text{белый} | B_1) P(B_1) + P(\text{белый} | B_2) P(B_2) = \frac{3}{5} \cdot 0.5 + \frac{4}{5} \cdot 0.5 = \frac{7}{10}
\]

## Теорема Байеса

Теорема Байеса позволяет пересчитывать условные вероятности событий. Она формулируется следующим образом:
\[
P(B | A) = \frac{P(A | B) P(B)}{P(A)}
\]
где \( P(A) > 0 \).

Теорема Байеса особенно полезна в задачах с обратной вероятностью, когда требуется найти вероятность события, вызвавшего наблюдаемый исход.

### Пример
Допустим, у нас есть тест на заболевание, который с вероятностью 99% верно определяет наличие заболевания и с вероятностью 95% верно показывает его отсутствие. Вероятность заболевания у случайного человека составляет 0.1%. Пусть:
- \( A \) — событие, что тест положительный.
- \( B \) — событие, что человек болен.

Тогда:
- \( P(A | B) = 0.99 \) — вероятность, что тест положительный при наличии заболевания.
- \( P(A | B') = 0.05 \) — вероятность, что тест положительный при отсутствии заболевания.
- \( P(B) = 0.001 \) — вероятность заболевания.

Теперь по формуле полной вероятности найдем \( P(A) \):
\[
P(A) = P(A | B) P(B) + P(A | B') P(B') = 0.99 \cdot 0.001 + 0.05 \cdot 0.999 = 0.05094
\]

Используя теорему Байеса, найдем \( P(B | A) \):
\[
P(B | A) = \frac{P(A | B) P(B)}{P(A)} = \frac{0.99 \cdot 0.001}{0.05094} \approx 0.0194
\]

Таким образом, вероятность того, что человек болен при положительном тесте, составляет около 1.94%.

## Заключение

Условная вероятность и связанные с ней формулы позволяют анализировать зависимости между событиями, оценивая вероятность наступления одного события с учетом другого. Эти понятия лежат в основе многих приложений в статистике и аналитике данных.
