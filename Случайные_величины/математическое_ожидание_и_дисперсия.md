# Математическое ожидание и дисперсия

**Математическое ожидание**, **дисперсия**, **ковариация** и **корреляция** — это ключевые числовые характеристики случайных величин, которые описывают их среднее значение, степень разброса и связь между величинами.

## Математическое ожидание

Математическое ожидание случайной величины \( X \), обозначаемое \( \mathbb{E}[X] \), представляет собой среднее значение, которое принимает \( X \) в долгосрочной перспективе.

### Определение

1. **Для дискретной случайной величины** \( X \), принимающей значения \( x_1, x_2, \dots \) с вероятностями \( p(x_1), p(x_2), \dots \), математическое ожидание определяется как:
   \[
   \mathbb{E}[X] = \sum_{i} x_i \cdot p(x_i)
   \]

2. **Для непрерывной случайной величины** \( X \) с плотностью вероятности \( f(x) \), математическое ожидание определяется интегралом:
   \[
   \mathbb{E}[X] = \int_{-\infty}^{\infty} x \cdot f(x) \, dx
   \]

### Свойства математического ожидания

- **Линейность**: Если \( X \) и \( Y \) — случайные величины, а \( a \) и \( b \) — константы, то:
  \[
  \mathbb{E}[aX + bY] = a\mathbb{E}[X] + b\mathbb{E}[Y]
  \]

- **Математическое ожидание константы**: Если \( c \) — постоянная величина, то \( \mathbb{E}[c] = c \).

### Пример
Пусть \( X \) — результат подбрасывания кубика, тогда:
\[
\mathbb{E}[X] = 1 \cdot \frac{1}{6} + 2 \cdot \frac{1}{6} + 3 \cdot \frac{1}{6} + 4 \cdot \frac{1}{6} + 5 \cdot \frac{1}{6} + 6 \cdot \frac{1}{6} = 3.5
\]

## Дисперсия

**Дисперсия** случайной величины \( X \), обозначаемая \( \text{Var}(X) \), характеризует разброс значений \( X \) относительно её математического ожидания.

### Определение

1. **Для дискретной случайной величины** \( X \), принимающей значения \( x_1, x_2, \dots \) с вероятностями \( p(x_1), p(x_2), \dots \), дисперсия определяется как:
   \[
   \text{Var}(X) = \mathbb{E}[(X - \mathbb{E}[X])^2] = \sum_{i} (x_i - \mathbb{E}[X])^2 \cdot p(x_i)
   \]

2. **Для непрерывной случайной величины** \( X \) с плотностью вероятности \( f(x) \), дисперсия определяется интегралом:
   \[
   \text{Var}(X) = \int_{-\infty}^{\infty} (x - \mathbb{E}[X])^2 \cdot f(x) \, dx
   \]

### Свойства дисперсии

1. **Неотрицательность**: Дисперсия всегда неотрицательна, так как это среднее значение квадрата отклонения:
   \[
   \text{Var}(X) \geq 0
   \]
   Дисперсия равна нулю только в случае, если \( X \) принимает одно фиксированное значение с вероятностью 1 (то есть случайная величина является константой).

2. **Смещение и масштаб**: Если \( a \) и \( b \) — константы, то:
   \[
   \text{Var}(aX + b) = a^2 \cdot \text{Var}(X)
   \]
   Это свойство показывает, что добавление константы \( b \) не влияет на дисперсию, а умножение на константу \( a \) увеличивает дисперсию в \( a^2 \) раз.

3. **Сумма независимых случайных величин**: Если \( X \) и \( Y \) — независимые случайные величины, то:
   \[
   \text{Var}(X + Y) = \text{Var}(X) + \text{Var}(Y)
   \]
   Для нескольких независимых случайных величин \( X_1, X_2, \dots, X_n \) верно:
   \[
   \text{Var}\left(\sum_{i=1}^{n} X_i\right) = \sum_{i=1}^{n} \text{Var}(X_i)
   \]

4. **Сумма зависимых случайных величин**: Если \( X \) и \( Y \) — зависимые случайные величины, то дисперсия их суммы выражается через ковариацию:
   \[
   \text{Var}(X + Y) = \text{Var}(X) + \text{Var}(Y) + 2 \cdot \text{Cov}(X, Y)
   \]

5. **Дисперсия суммы с коррелированными случайными величинами**: Если корреляция между \( X \) и \( Y \) обозначена как \( \rho(X, Y) \), то дисперсия суммы также может быть выражена через коэффициент корреляции:
   \[
   \text{Var}(X + Y) = \text{Var}(X) + \text{Var}(Y) + 2 \cdot \rho(X, Y) \cdot \sigma_X \cdot \sigma_Y
   \]
   где \( \sigma_X \) и \( \sigma_Y \) — стандартные отклонения \( X \) и \( Y \).

6. **Аддитивность для независимых идентично распределенных случайных величин**: Если \( X_1, X_2, \dots, X_n \) — независимые и одинаково распределенные случайные величины с дисперсией \( \text{Var}(X) \), то дисперсия их суммы будет равна:
   \[
   \text{Var}\left(\sum_{i=1}^{n} X_i\right) = n \cdot \text{Var}(X)
   \]

Эти свойства дисперсии помогают упростить вычисления и анализ при работе с суммами и линейными комбинациями случайных величин, а также при масштабировании и смещении случайных величин.


## Ковариация и корреляция

### Ковариация

**Ковариация** измеряет степень зависимости между двумя случайными величинами \( X \) и \( Y \). Обозначается как \( \text{Cov}(X, Y) \) и определяется как:
\[
\text{Cov}(X, Y) = \mathbb{E}[(X - \mathbb{E}[X])(Y - \mathbb{E}[Y])]
\]
Если \( \text{Cov}(X, Y) > 0 \), то величины \( X \) и \( Y \) имеют тенденцию увеличиваться вместе. Если \( \text{Cov}(X, Y) < 0 \), то они изменяются в противоположных направлениях.

#### Свойства ковариации

1. **Ковариация независимых величин**: Если \( X \) и \( Y \) — независимые случайные величины, то:
   \[
   \text{Cov}(X, Y) = 0
   \]
   (однако обратное неверно: ковариация может быть равна нулю для зависимых величин).

2. **Линейность**: Для любых случайных величин \( X \) и \( Y \) и констант \( a \) и \( b \):
   \[
   \text{Cov}(aX, bY) = ab \cdot \text{Cov}(X, Y)
   \]

3. **Свойство суммы**: Если \( Z = X + Y \), то ковариация между \( Z \) и другой случайной величиной \( W \) равна:
   \[
   \text{Cov}(Z, W) = \text{Cov}(X, W) + \text{Cov}(Y, W)
   \]

### Корреляция

**Корреляция** — это нормированное значение ковариации, которое принимает значения от -1 до 1 и измеряет силу линейной зависимости между \( X \) и \( Y \). Обозначается \( \rho(X, Y) \) и вычисляется как:
\[
\rho(X, Y) = \frac{\text{Cov}(X, Y)}{\sigma_X \sigma_Y}
\]
где \( \sigma_X \) и \( \sigma_Y \) — среднеквадратичные отклонения \( X \) и \( Y \). Значения корреляции, близкие к 1 или -1, указывают на сильную линейную зависимость, тогда как значения близкие к 0 указывают на слабую или отсутствующую линейную зависимость.

#### Свойства корреляции

1. **Ограниченность**: Корреляция всегда находится в пределах от -1 до 1:
   \[
   -1 \leq \rho(X, Y) \leq 1
   \]
   Значение \( \rho(X, Y) = 1 \) соответствует идеальной положительной линейной зависимости, а \( \rho(X, Y) = -1 \) — идеальной отрицательной линейной зависимости.

2. **Независимость**: Если \( X \) и \( Y \) — независимые случайные величины, то \( \rho(X, Y) = 0 \) (но обратное неверно).

3. **Корреляция идентичных величин**: Корреляция случайной величины с самой собой равна 1:
   \[
   \rho(X, X) = 1
   \]

4. **Неизменность при линейном преобразовании**: Корреляция не изменяется при линейных преобразованиях. Для любых констант \( a, b, c, d \), где \( a, c \neq 0 \):
   \[
   \rho(aX + b, cY + d) = \rho(X, Y)
   \]

Эти свойства помогают более глубоко понимать и интерпретировать взаимосвязи между случайными величинами.


### Свойства дисперсии

1. **Неотрицательность**: Дисперсия всегда неотрицательна, так как это среднее значение квадрата отклонения:
   \[
   \text{Var}(X) \geq 0
   \]
   Дисперсия равна нулю только в случае, если \( X \) принимает одно фиксированное значение с вероятностью 1 (то есть случайная величина является константой).

2. **Смещение и масштаб**: Если \( a \) и \( b \) — константы, то:
   \[
   \text{Var}(aX + b) = a^2 \cdot \text{Var}(X)
   \]
   Это свойство показывает, что добавление константы \( b \) не влияет на дисперсию, а умножение на константу \( a \) увеличивает дисперсию в \( a^2 \) раз.

3. **Сумма независимых случайных величин**: Если \( X \) и \( Y \) — независимые случайные величины, то:
   \[
   \text{Var}(X + Y) = \text{Var}(X) + \text{Var}(Y)
   \]
   Для нескольких независимых случайных величин \( X_1, X_2, \dots, X_n \) верно:
   \[
   \text{Var}\left(\sum_{i=1}^{n} X_i\right) = \sum_{i=1}^{n} \text{Var}(X_i)
   \]

4. **Сумма зависимых случайных величин**: Если \( X \) и \( Y \) — зависимые случайные величины, то дисперсия их суммы выражается через ковариацию:
   \[
   \text{Var}(X + Y) = \text{Var}(X) + \text{Var}(Y) + 2 \cdot \text{Cov}(X, Y)
   \]

5. **Разность случайных величин**: Для разности случайных величин \( X - Y \) дисперсия выражается как:
   \[
   \text{Var}(X - Y) = \text{Var}(X) + \text{Var}(Y) - 2 \cdot \text{Cov}(X, Y)
   \]
   Если \( X \) и \( Y \) независимы, то \( \text{Cov}(X, Y) = 0 \), и дисперсия разности равна сумме дисперсий, как и для суммы.

6. **Дисперсия суммы с коррелированными случайными величинами**: Если корреляция между \( X \) и \( Y \) обозначена как \( \rho(X, Y) \), то дисперсия суммы также может быть выражена через коэффициент корреляции:
   \[
   \text{Var}(X + Y) = \text{Var}(X) + \text{Var}(Y) + 2 \cdot \rho(X, Y) \cdot \sigma_X \cdot \sigma_Y
   \]
   где \( \sigma_X \) и \( \sigma_Y \) — стандартные отклонения \( X \) и \( Y \).

7. **Аддитивность для независимых идентично распределенных случайных величин**: Если \( X_1, X_2, \dots, X_n \) — независимые и одинаково распределенные случайные величины с дисперсией \( \text{Var}(X) \), то дисперсия их суммы будет равна:
   \[
   \text{Var}\left(\sum_{i=1}^{n} X_i\right) = n \cdot \text{Var}(X)
   \]

Эти свойства завершают описание дисперсии, добавляя правила для работы с суммами, разностями, зависимыми и независимыми случайными величинами, а также для масштабирования и смещения случайных величин.

## Среднеквадратичное отклонение

**Среднеквадратичное отклонение** — это квадратный корень из дисперсии, обозначается как \( \sigma(X) \) или просто \( \sigma \):
\[
\sigma(X) = \sqrt{\text{Var}(X)}
\]
Среднеквадратичное отклонение характеризует разброс значений и выражается в тех же единицах, что и сама случайная величина \( X \).

## Заключение

Математическое ожидание, дисперсия, ковариация и корреляция являются основными характеристиками случайных величин, описывающими их среднее значение, степень разброса и взаимосвязь. Эти показатели играют ключевую роль в анализе данных и статистике.
